<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Reactive Blob Demo</title>
    <!-- Load Three.js from CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.155.0/three.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            overflow: hidden;
            font-family: 'Arial', sans-serif;
            background-color: #000;
            color: white;
            height: 100vh;
        }

        .app {
            display: flex;
            flex-direction: column;
            height: 100vh;
        }

        .canvas-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        .controls {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            padding: 20px;
            background-color: rgba(0, 0, 0, 0.7);
            text-align: center;
            z-index: 10;
        }

        h1 {
            margin: 0 0 10px;
            font-size: 24px;
            color: #fff;
        }

        p {
            margin-bottom: 20px;
            color: #aaa;
        }

        .control-button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s ease;
        }

        .control-button:hover {
            background-color: #2980b9;
        }

        .control-button.active {
            background-color: #e74c3c;
        }

        .audio-meter {
            margin: 20px auto;
            width: 80%;
            max-width: 300px;
            height: 10px;
            background-color: #222;
            border-radius: 5px;
            overflow: hidden;
        }

        .audio-level {
            height: 100%;
            width: 0%;
            background: linear-gradient(to right, #3498db, #9b59b6, #e74c3c);
            transition: width 0.1s ease;
        }
        
        .loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 24px;
            color: white;
        }
    </style>
</head>
<body>
    <div id="app">
        <div class="canvas-container" id="canvas-container">
            <!-- Three.js canvas will be inserted here -->
        </div>
        
        <div class="controls">
            <h1>Voice Reactive Blob</h1>
            <p>Speak or make sounds to interact with the blob</p>
            
            <button id="mic-button" class="control-button">
                Enable Microphone
            </button>
            
            <div class="audio-meter">
                <div id="audio-level" class="audio-level"></div>
            </div>
        </div>
    </div>

    <div id="loading" class="loading">Loading... Please wait.</div>

    <script>
        // Wait for the page to load
        window.addEventListener('load', function() {
            // Check if Three.js loaded correctly
            if (typeof THREE === 'undefined') {
                document.getElementById('loading').textContent = 'Three.js failed to load. Please refresh the page.';
                return;
            }
            
            init();
        });
        
        function init() {
            // DOM elements
            const loadingElement = document.getElementById('loading');
            const micButton = document.getElementById('mic-button');
            const audioLevelElement = document.getElementById('audio-level');
            const canvasContainer = document.getElementById('canvas-container');
            
            // Audio state variables
            let isListening = false;
            let audioLevel = 0;
            let audioContext;
            let analyser;
            let microphone;
            
            // Three.js setup
            const scene = new THREE.Scene();
            const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            canvasContainer.appendChild(renderer.domElement);
            
            // Add lights
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);
            
            const pointLight = new THREE.PointLight(0xffffff, 1);
            pointLight.position.set(10, 10, 10);
            scene.add(pointLight);
            
            // Position camera
            camera.position.z = 5;
            
            // Vertex shader code
            const vertexShader = `
                uniform float u_time;
                uniform float u_intensity;
                uniform float u_audioLevel;
                
                varying vec2 vUv;
                varying float vDisplacement;
                
                // Classic Perlin 3D Noise 
                // by Stefan Gustavson
                vec4 permute(vec4 x) {
                    return mod(((x*34.0)+1.0)*x, 289.0);
                }
                vec4 taylorInvSqrt(vec4 r) {
                    return 1.79284291400159 - 0.85373472095314 * r;
                }
                vec3 fade(vec3 t) {
                    return t*t*t*(t*(t*6.0-15.0)+10.0);
                }
                
                float cnoise(vec3 P) {
                    vec3 Pi0 = floor(P); // Integer part for indexing
                    vec3 Pi1 = Pi0 + vec3(1.0); // Integer part + 1
                    Pi0 = mod(Pi0, 289.0);
                    Pi1 = mod(Pi1, 289.0);
                    vec3 Pf0 = fract(P); // Fractional part for interpolation
                    vec3 Pf1 = Pf0 - vec3(1.0); // Fractional part - 1.0
                    vec4 ix = vec4(Pi0.x, Pi1.x, Pi0.x, Pi1.x);
                    vec4 iy = vec4(Pi0.yy, Pi1.yy);
                    vec4 iz0 = Pi0.zzzz;
                    vec4 iz1 = Pi1.zzzz;
                    vec4 ixy = permute(permute(ix) + iy);
                    vec4 ixy0 = permute(ixy + iz0);
                    vec4 ixy1 = permute(ixy + iz1);
                    vec4 gx0 = ixy0 / 7.0;
                    vec4 gy0 = fract(floor(gx0) / 7.0) - 0.5;
                    gx0 = fract(gx0);
                    vec4 gz0 = vec4(0.5) - abs(gx0) - abs(gy0);
                    vec4 sz0 = step(gz0, vec4(0.0));
                    gx0 -= sz0 * (step(0.0, gx0) - 0.5);
                    gy0 -= sz0 * (step(0.0, gy0) - 0.5);
                    vec4 gx1 = ixy1 / 7.0;
                    vec4 gy1 = fract(floor(gx1) / 7.0) - 0.5;
                    gx1 = fract(gx1);
                    vec4 gz1 = vec4(0.5) - abs(gx1) - abs(gy1);
                    vec4 sz1 = step(gz1, vec4(0.0));
                    gx1 -= sz1 * (step(0.0, gx1) - 0.5);
                    gy1 -= sz1 * (step(0.0, gy1) - 0.5);
                    vec3 g000 = vec3(gx0.x,gy0.x,gz0.x);
                    vec3 g100 = vec3(gx0.y,gy0.y,gz0.y);
                    vec3 g010 = vec3(gx0.z,gy0.z,gz0.z);
                    vec3 g110 = vec3(gx0.w,gy0.w,gz0.w);
                    vec3 g001 = vec3(gx1.x,gy1.x,gz1.x);
                    vec3 g101 = vec3(gx1.y,gy1.y,gz1.y);
                    vec3 g011 = vec3(gx1.z,gy1.z,gz1.z);
                    vec3 g111 = vec3(gx1.w,gy1.w,gz1.w);
                    vec4 norm0 = taylorInvSqrt(vec4(dot(g000, g000), dot(g010, g010), dot(g100, g100), dot(g110, g110)));
                    g000 *= norm0.x;
                    g010 *= norm0.y;
                    g100 *= norm0.z;
                    g110 *= norm0.w;
                    vec4 norm1 = taylorInvSqrt(vec4(dot(g001, g001), dot(g011, g011), dot(g101, g101), dot(g111, g111)));
                    g001 *= norm1.x;
                    g011 *= norm1.y;
                    g101 *= norm1.z;
                    g111 *= norm1.w;
                    float n000 = dot(g000, Pf0);
                    float n100 = dot(g100, vec3(Pf1.x, Pf0.yz));
                    float n010 = dot(g010, vec3(Pf0.x, Pf1.y, Pf0.z));
                    float n110 = dot(g110, vec3(Pf1.xy, Pf0.z));
                    float n001 = dot(g001, vec3(Pf0.xy, Pf1.z));
                    float n101 = dot(g101, vec3(Pf1.x, Pf0.y, Pf1.z));
                    float n011 = dot(g011, vec3(Pf0.x, Pf1.yz));
                    float n111 = dot(g111, Pf1);
                    vec3 fade_xyz = fade(Pf0);
                    vec4 n_z = mix(vec4(n000, n100, n010, n110), vec4(n001, n101, n011, n111), fade_xyz.z);
                    vec2 n_yz = mix(n_z.xy, n_z.zw, fade_xyz.y);
                    float n_xyz = mix(n_yz.x, n_yz.y, fade_xyz.x); 
                    return 2.2 * n_xyz;
                }
                // End of Perlin Noise Code
                
                void main() {
                    vUv = uv;
                    
                    // Add audio responsiveness to the noise
                    float noiseFreq = 1.0 + u_audioLevel * 2.0;
                    vDisplacement = cnoise(position * noiseFreq + vec3(2.0 * u_time));
                    
                    // Calculate displacement amount with audio influence
                    float displacementAmount = u_intensity * (1.0 + u_audioLevel * 2.0);
                    vec3 newPosition = position + normal * (displacementAmount * vDisplacement);
                    
                    vec4 modelPosition = modelMatrix * vec4(newPosition, 1.0);
                    vec4 viewPosition = viewMatrix * modelPosition;
                    vec4 projectedPosition = projectionMatrix * viewPosition;
                    
                    gl_Position = projectedPosition;
                }
            `;
            
            // Fragment shader code
            const fragmentShader = `
                uniform float u_intensity;
                uniform float u_time;
                uniform float u_audioLevel;
                
                varying vec2 vUv;
                varying float vDisplacement;
                
                void main() {
                    // Base distortion effect
                    float distort = 2.0 * vDisplacement * u_intensity * sin(vUv.y * 10.0 + u_time);
                    
                    // Color based on audio level
                    vec3 quietColor = vec3(0.0, 0.4, 0.8); // Blue when quiet
                    vec3 mediumColor = vec3(0.8, 0.4, 0.8); // Purple for medium
                    vec3 loudColor = vec3(0.9, 0.2, 0.2);  // Red when loud
                    
                    // Mix colors based on audio level
                    vec3 audioColor;
                    if (u_audioLevel > 0.6) {
                        audioColor = mix(mediumColor, loudColor, (u_audioLevel - 0.6) / 0.4);
                    } else {
                        audioColor = mix(quietColor, mediumColor, u_audioLevel / 0.6);
                    }
                    
                    // Apply distortion and uv-based coloring
                    // Convert vec2 to float by taking the length of the centered UV coordinates
                    float uvDistFromCenter = length(vUv - 0.5) * 2.0;
                    // Mix based on this distance and the distortion
                    float mixFactor = uvDistFromCenter * (1.0 - distort);
                    vec3 baseColor = mix(audioColor, vec3(1.0, 1.0, 1.0), mixFactor);
                    
                    // Add pulsing effect based on audio
                    float pulse = sin(u_time * 10.0) * 0.5 + 0.5;
                    float glow = u_audioLevel * pulse * 0.3;
                    vec3 color = baseColor + audioColor * glow;
                    
                    // Ensure colors are in valid range
                    color = clamp(color, vec3(0.0), vec3(1.0));
                    
                    gl_FragColor = vec4(color, 1.0);
                }
            `;
            
            // Create uniforms for the shaders
            const uniforms = {
                u_time: { value: 0 },
                u_intensity: { value: 0.3 },
                u_audioLevel: { value: 0 }
            };
            
            // Create the blob mesh
            const geometry = new THREE.IcosahedronGeometry(2, 20);
            const material = new THREE.ShaderMaterial({
                vertexShader: vertexShader,
                fragmentShader: fragmentShader,
                uniforms: uniforms
            });
            
            const blob = new THREE.Mesh(geometry, material);
            scene.add(blob);
            
            // Track mouse hover
            let hover = false;
            
            renderer.domElement.addEventListener('mouseover', () => {
                hover = true;
            });
            
            renderer.domElement.addEventListener('mouseout', () => {
                hover = false;
            });
            
            // Animation loop
            const clock = new THREE.Clock();
            
            function animate() {
                requestAnimationFrame(animate);
                
                // Update uniforms
                uniforms.u_time.value = 0.4 * clock.getElapsedTime();
                
                // Target intensity based on hover and audio
                const targetIntensity = hover ? 0.8 : 0.15 + audioLevel * 0.85;
                uniforms.u_intensity.value += (targetIntensity - uniforms.u_intensity.value) * 0.05;
                uniforms.u_audioLevel.value = audioLevel;
                
                // Update blob scale based on audio
                const scale = 1.5 + audioLevel * 0.5;
                blob.scale.set(scale, scale, scale);
                
                // Add rotation based on audio
                blob.rotation.y += 0.002 + audioLevel * 0.01;
                blob.rotation.z += 0.001 + audioLevel * 0.005;
                
                renderer.render(scene, camera);
            }
            
            // Start animation
            animate();
            
            // Handle window resize
            window.addEventListener('resize', () => {
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(window.innerWidth, window.innerHeight);
            });
            
            // Microphone button click handler
            micButton.addEventListener('click', () => {
                if (isListening) {
                    stopListening();
                    micButton.textContent = 'Enable Microphone';
                    micButton.classList.remove('active');
                } else {
                    startListening();
                    micButton.textContent = 'Disable Microphone';
                    micButton.classList.add('active');
                }
            });
            
            // Start audio analysis
            async function startListening() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    isListening = true;
                    
                    // Create audio context and analyzer
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    microphone = audioContext.createMediaStreamSource(stream);
                    
                    microphone.connect(analyser);
                    analyser.fftSize = 256;
                    
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    
                    // Update audio level periodically
                    function updateAudioLevel() {
                        if (!isListening) return;
                        
                        analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume level
                        let sum = 0;
                        for (let i = 0; i < bufferLength; i++) {
                            sum += dataArray[i];
                        }
                        const avg = sum / bufferLength;
                        
                        // Normalize between 0 and 1 with some amplification
                        audioLevel = Math.min(1, avg / 128);
                        
                        // Update visual audio meter
                        audioLevelElement.style.width = `${audioLevel * 100}%`;
                        
                        requestAnimationFrame(updateAudioLevel);
                    }
                    
                    updateAudioLevel();
                } catch (err) {
                    console.error("Error accessing microphone:", err);
                    alert("Please allow microphone access to use voice reactivity");
                }
            }
            
            // Stop audio analysis
            function stopListening() {
                isListening = false;
                audioLevel = 0;
                audioLevelElement.style.width = '0%';
                
                if (microphone) {
                    microphone.disconnect();
                }
                if (audioContext) {
                    audioContext.close();
                }
            }
            
            // Remove loading message
            loadingElement.style.display = 'none';
        }
    </script>
</body>
</html>
