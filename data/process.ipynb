{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the process for file: /home/hansen/workspace/hackathon/hackson-voice-agent/data/data.csv\n",
      "Using Customer ID column: '客代'\n",
      "Attempting to use encoding: 'utf-8'\n",
      "Output directory: 'customer_files'\n",
      "Reading CSV file: /home/hansen/workspace/hackathon/hackson-voice-agent/data/data.csv...\n",
      "Successfully read CSV file.\n",
      "Validated column '客代'.\n",
      "Created output directory: 'customer_files'\n",
      "Found 100 unique customer IDs.\n",
      "Splitting data and saving files...\n",
      "Successfully created 100 individual customer CSV files in 'customer_files'.\n",
      "Creating zip archive: customer_files.zip...\n",
      "Successfully created zip archive: customer_files.zip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "def split_csv_by_customer_id(\n",
    "    input_csv_path: str,\n",
    "    customer_id_column: str,\n",
    "    output_dir: str = 'customer_files',\n",
    "    encoding: str = 'utf-8' # Common encoding for Traditional Chinese\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, splits it into multiple CSV files based on unique values\n",
    "    in the specified customer ID column, saves them into a directory,\n",
    "    and creates a zip archive of that directory.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file.\n",
    "        customer_id_column (str): The exact name of the column containing customer IDs.\n",
    "        output_dir (str): The name of the directory to save the individual CSV files.\n",
    "        encoding (str): The character encoding to use when reading/writing CSVs.\n",
    "    \"\"\"\n",
    "    print(f\"Starting the process for file: {input_csv_path}\")\n",
    "    print(f\"Using Customer ID column: '{customer_id_column}'\")\n",
    "    print(f\"Attempting to use encoding: '{encoding}'\")\n",
    "    print(f\"Output directory: '{output_dir}'\")\n",
    "\n",
    "    try:\n",
    "        # --- 1. Read the input CSV file ---\n",
    "        print(f\"Reading CSV file: {input_csv_path}...\")\n",
    "        # Explicitly set dtype for the ID column to string if possible,\n",
    "        # otherwise pandas might infer numeric types incorrectly.\n",
    "        # If the column doesn't exist, this will likely fail later anyway.\n",
    "        try:\n",
    "            df = pd.read_csv(input_csv_path, encoding=encoding, dtype={customer_id_column: str})\n",
    "        except ValueError as ve:\n",
    "            # If specifying dtype fails (e.g., column not found yet), read without it\n",
    "            print(f\"Warning: Could not pre-specify dtype for '{customer_id_column}'. Reading without dtype specification. Error: {ve}\")\n",
    "            df = pd.read_csv(input_csv_path, encoding=encoding)\n",
    "\n",
    "        print(\"Successfully read CSV file.\")\n",
    "\n",
    "        # --- 2. Validate Customer ID column ---\n",
    "        if customer_id_column not in df.columns:\n",
    "            print(f\"Error: Column '{customer_id_column}' not found in the CSV file.\")\n",
    "            print(f\"Available columns are: {df.columns.tolist()}\")\n",
    "            return\n",
    "        print(f\"Validated column '{customer_id_column}'.\")\n",
    "\n",
    "        # --- 3. Create output directory ---\n",
    "        if os.path.exists(output_dir):\n",
    "            print(f\"Output directory '{output_dir}' already exists. Removing existing directory...\")\n",
    "            shutil.rmtree(output_dir) # Remove old directory to avoid mixing files\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: '{output_dir}'\")\n",
    "\n",
    "        # --- 4. Get unique customer IDs ---\n",
    "        # Convert column to string explicitly and handle potential NaN values\n",
    "        unique_ids = df[customer_id_column].astype(str).unique()\n",
    "        # Remove potential 'nan' strings if they resulted from conversion\n",
    "        unique_ids = [id_val for id_val in unique_ids if id_val.lower() != 'nan']\n",
    "\n",
    "        print(f\"Found {len(unique_ids)} unique customer IDs.\")\n",
    "        if not unique_ids:\n",
    "            print(\"Warning: No unique customer IDs found. No files will be created.\")\n",
    "            return\n",
    "\n",
    "        # --- 5. Split data and save to individual files ---\n",
    "        print(\"Splitting data and saving files...\")\n",
    "        file_count = 0\n",
    "        for customer_id in unique_ids:\n",
    "            # Filter dataframe for the current customer ID\n",
    "            # Ensure comparison is done correctly (string vs string)\n",
    "            customer_df = df[df[customer_id_column].astype(str) == customer_id]\n",
    "\n",
    "            if not customer_df.empty:\n",
    "                # Sanitize customer_id for use as a filename\n",
    "                # Remove/replace characters invalid for filenames\n",
    "                sanitized_id = re.sub(r'[\\\\/*?:\"<>|]', '_', str(customer_id))\n",
    "                # Ensure filename isn't empty after sanitization\n",
    "                if not sanitized_id:\n",
    "                    sanitized_id = f\"customer_{file_count+1}\" # Fallback filename\n",
    "\n",
    "                output_filename = f\"{sanitized_id}.csv\"\n",
    "                output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "                # Save the filtered data to a new CSV\n",
    "                customer_df.to_csv(output_filepath, index=False, encoding=encoding)\n",
    "                file_count += 1\n",
    "\n",
    "        print(f\"Successfully created {file_count} individual customer CSV files in '{output_dir}'.\")\n",
    "\n",
    "        # --- 6. Zip the output directory ---\n",
    "        if file_count > 0:\n",
    "            zip_filename = f\"{output_dir}.zip\"\n",
    "            print(f\"Creating zip archive: {zip_filename}...\")\n",
    "            shutil.make_archive(output_dir, 'zip', output_dir)\n",
    "            print(f\"Successfully created zip archive: {zip_filename}\")\n",
    "        else:\n",
    "            print(\"No files were created, skipping zip archive creation.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The input file '{input_csv_path}' was not found.\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error: Could not decode the file using encoding '{encoding}'.\")\n",
    "        print(\"Please verify the file encoding and provide the correct one.\")\n",
    "    except KeyError:\n",
    "        # This might catch cases where the column name was slightly off even if it passed initial check\n",
    "         print(f\"Error: A KeyError occurred, likely related to accessing column '{customer_id_column}'.\")\n",
    "         print(\"Please double-check the exact column name.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# --- How to use the function ---\n",
    "# 1. Make sure the input CSV file is available in the environment.\n",
    "# 2. Adjust the parameters if needed (especially customer_id_column).\n",
    "input_file = '/home/hansen/workspace/hackathon/hackson-voice-agent/data/data.csv'\n",
    "assumed_id_column = '客代' # IMPORTANT: Change this if '客代' is incorrect!\n",
    "\n",
    "# Run the function\n",
    "split_csv_by_customer_id(input_csv_path=input_file, customer_id_column=assumed_id_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Profile: 客代 23\n",
      "\n",
      "保健:\n",
      "  可推薦商品類別: 美容養顏, 強化靈活關節, 提升調節免疫力, 體重管理\n",
      "  是否有高健康意識: 是\n",
      "\n",
      "基本類別:\n",
      "  居住縣市: 台中市太平區\n",
      "  年齡區間: 60-69\n",
      "  性別: 女\n",
      "  星座: 射手座\n",
      "  會員年資分組: 20年以上-25年以下\n",
      "  會員等級: A級會員\n",
      "  職業: 退休族\n",
      "\n",
      "宗教商品:\n",
      "  有無宗教商品偏好: 有\n",
      "\n",
      "寵物:\n",
      "  有無養寵物: 無\n",
      "\n",
      "生活:\n",
      "  有無生活用品偏好: 有\n",
      "\n",
      "美容:\n",
      "  有無美容偏好: 有\n",
      "  美妝保養類型偏好: 護膚SPA\n",
      "\n",
      "食品:\n",
      "  有無食品偏好: 有\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def format_customer_data_to_txt(csv_data_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms CSV data for a single customer into a structured TXT format.\n",
    "\n",
    "    Args:\n",
    "        csv_data_string: A string containing the CSV data for one customer.\n",
    "                         Expected headers: 客代,標籤分類1,標籤分類2,標籤名稱,標籤值\n",
    "\n",
    "    Returns:\n",
    "        A string containing the formatted customer profile in TXT format.\n",
    "        Returns an error message string if processing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use StringIO to read the CSV data string into a pandas DataFrame\n",
    "        data_io = io.StringIO(csv_data_string)\n",
    "        df = pd.read_csv(data_io)\n",
    "\n",
    "        # --- Basic Validation ---\n",
    "        required_columns = ['客代', '標籤分類1', '標籤名稱', '標籤值']\n",
    "        if not all(col in df.columns for col in required_columns):\n",
    "            return f\"Error: Input CSV data is missing one or more required columns: {required_columns}\"\n",
    "\n",
    "        if df.empty:\n",
    "            return \"Error: Input CSV data is empty.\"\n",
    "\n",
    "        # Get the customer ID (should be the same for all rows)\n",
    "        customer_id = df['客代'].iloc[0]\n",
    "\n",
    "        # --- Group data and aggregate values ---\n",
    "        # Group by category and attribute name, collect values into a list\n",
    "        grouped = df.groupby(['標籤分類1', '標籤名稱'])['標籤值'].apply(list).reset_index()\n",
    "\n",
    "        # --- Build the output TXT string ---\n",
    "        output_lines = []\n",
    "        output_lines.append(f\"Customer Profile: 客代 {customer_id}\")\n",
    "        output_lines.append(\"\") # Add a blank line\n",
    "\n",
    "        # Iterate through the primary categories (標籤分類1)\n",
    "        for category1 in grouped['標籤分類1'].unique():\n",
    "            output_lines.append(f\"{category1}:\")\n",
    "            # Get attributes and values within this category\n",
    "            category_data = grouped[grouped['標籤分類1'] == category1]\n",
    "            for _, row in category_data.iterrows():\n",
    "                key = row['標籤名稱']\n",
    "                # Join list of values with a comma, convert items to string first\n",
    "                value = \", \".join(map(str, row['標籤值']))\n",
    "                output_lines.append(f\"  {key}: {value}\") # Indent attributes\n",
    "            output_lines.append(\"\") # Add a blank line after each category section\n",
    "\n",
    "        return \"\\n\".join(output_lines).strip() # Join lines and remove trailing whitespace\n",
    "\n",
    "    except pd.errors.EmptyDataError:\n",
    "        return \"Error: No columns to parse from CSV data string.\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred during formatting: {e}\"\n",
    "\n",
    "def process_csv_folder_to_txt(\n",
    "    input_csv_dir: str,\n",
    "    output_txt_dir: str,\n",
    "    csv_encoding: str = 'big5' # Encoding to read the source CSVs\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Processes a folder of customer CSV files, formats each using\n",
    "    format_customer_data_to_txt, and saves the results as TXT files\n",
    "    in a specified output directory.\n",
    "\n",
    "    Args:\n",
    "        input_csv_dir (str): Path to the directory containing individual customer CSV files.\n",
    "        output_txt_dir (str): Path to the directory where formatted TXT files will be saved.\n",
    "        csv_encoding (str): Encoding used to read the input CSV files.\n",
    "    \"\"\"\n",
    "    print(f\"Starting batch processing...\")\n",
    "    print(f\"Input CSV directory: '{input_csv_dir}'\")\n",
    "    print(f\"Output TXT directory: '{output_txt_dir}'\")\n",
    "    print(f\"Using CSV reading encoding: '{csv_encoding}'\")\n",
    "\n",
    "    # --- Create output directory ---\n",
    "    if not os.path.exists(output_txt_dir):\n",
    "        os.makedirs(output_txt_dir)\n",
    "        print(f\"Created output directory: '{output_txt_dir}'\")\n",
    "    else:\n",
    "        print(f\"Output directory '{output_txt_dir}' already exists.\")\n",
    "\n",
    "    # --- Find all CSV files in the input directory ---\n",
    "    csv_files = glob.glob(os.path.join(input_csv_dir, '*.csv'))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"Warning: No CSV files found in '{input_csv_dir}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(csv_files)} CSV files to process.\")\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    # --- Loop through each CSV file ---\n",
    "    for csv_filepath in csv_files:\n",
    "        base_filename = os.path.basename(csv_filepath)\n",
    "        print(f\"Processing '{base_filename}'...\")\n",
    "\n",
    "        try:\n",
    "            # --- Read the CSV file content into a string ---\n",
    "            with open(csv_filepath, 'r', encoding=csv_encoding) as f:\n",
    "                csv_content_string = f.read()\n",
    "\n",
    "            # --- Format the data using the helper function ---\n",
    "            formatted_text = format_customer_data_to_txt(csv_content_string)\n",
    "\n",
    "            # --- Check for errors from the formatting function ---\n",
    "            if formatted_text.startswith(\"Error:\"):\n",
    "                print(f\"  Error formatting '{base_filename}': {formatted_text}\")\n",
    "                error_count += 1\n",
    "                continue # Skip to the next file\n",
    "\n",
    "            # --- Construct output TXT filename and path ---\n",
    "            txt_filename = os.path.splitext(base_filename)[0] + '.txt'\n",
    "            output_filepath = os.path.join(output_txt_dir, txt_filename)\n",
    "\n",
    "            # --- Write the formatted text to the TXT file ---\n",
    "            # Use UTF-8 for writing TXT files, as it's widely compatible\n",
    "            with open(output_filepath, 'w', encoding='utf-8') as f_out:\n",
    "                f_out.write(formatted_text)\n",
    "\n",
    "            success_count += 1\n",
    "            # print(f\"  Successfully created '{txt_filename}'\") # Optional: more verbose logging\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  Error: File not found '{csv_filepath}' (should not happen with glob).\")\n",
    "            error_count += 1\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"  Error: Could not decode '{base_filename}' using encoding '{csv_encoding}'. Try a different encoding.\")\n",
    "            error_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred processing '{base_filename}': {e}\")\n",
    "            error_count += 1\n",
    "\n",
    "    print(\"\\nBatch processing finished.\")\n",
    "    print(f\"Successfully processed: {success_count} files.\")\n",
    "    print(f\"Errors encountered: {error_count} files.\")\n",
    "\n",
    "    # --- Optional: Zip the output directory ---\n",
    "    if success_count > 0:\n",
    "        try:\n",
    "            zip_filename = f\"{output_txt_dir}.zip\"\n",
    "            print(f\"\\nCreating zip archive: {zip_filename}...\")\n",
    "            shutil.make_archive(output_txt_dir, 'zip', output_txt_dir)\n",
    "            print(f\"Successfully created zip archive: {zip_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create zip file: {e}\")\n",
    "\n",
    "# --- Example Usage with your provided data ---\n",
    "sample_customer_csv_data = \"\"\"客代,標籤分類1,標籤分類2,標籤名稱,標籤值\n",
    "23,基本類別,基本類別,性別,女\n",
    "23,基本類別,基本類別,年齡區間,60-69\n",
    "23,基本類別,基本類別,星座,射手座\n",
    "23,基本類別,基本類別,居住縣市,台中市太平區\n",
    "23,基本類別,基本類別,會員等級,A級會員\n",
    "23,基本類別,基本類別,會員年資分組,20年以上-25年以下\n",
    "23,基本類別,基本類別,職業,退休族\n",
    "23,保健,保健功效,可推薦商品類別,美容養顏\n",
    "23,保健,保健功效,可推薦商品類別,強化靈活關節\n",
    "23,保健,保健功效,可推薦商品類別,提升調節免疫力\n",
    "23,保健,保健功效,可推薦商品類別,體重管理\n",
    "23,保健,高健康意識,是否有高健康意識,是\n",
    "23,宗教商品,宗教風水偏好,有無宗教商品偏好,有\n",
    "23,生活,生活用品偏好,有無生活用品偏好,有\n",
    "23,美容,美容偏好,有無美容偏好,有\n",
    "23,美容,美容偏好,美妝保養類型偏好,護膚SPA\n",
    "23,食品,食品偏好,有無食品偏好,有\n",
    "23,寵物,寵物偏好,有無養寵物,無\"\"\"\n",
    "\n",
    "formatted_text = format_customer_data_to_txt(sample_customer_csv_data)\n",
    "print(formatted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing...\n",
      "Input CSV directory: '/home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_csv'\n",
      "Output TXT directory: '/home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_txt'\n",
      "Using CSV reading encoding: 'utf-8'\n",
      "Output directory '/home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_txt' already exists.\n",
      "Found 100 CSV files to process.\n",
      "Processing '41.csv'...\n",
      "Processing '15.csv'...\n",
      "Processing '76.csv'...\n",
      "Processing '16.csv'...\n",
      "Processing '56.csv'...\n",
      "Processing '27.csv'...\n",
      "Processing '85.csv'...\n",
      "Processing '92.csv'...\n",
      "Processing '79.csv'...\n",
      "Processing '11.csv'...\n",
      "Processing '12.csv'...\n",
      "Processing '90.csv'...\n",
      "Processing '66.csv'...\n",
      "Processing '8.csv'...\n",
      "Processing '72.csv'...\n",
      "Processing '89.csv'...\n",
      "Processing '23.csv'...\n",
      "Processing '30.csv'...\n",
      "Processing '46.csv'...\n",
      "Processing '20.csv'...\n",
      "Processing '55.csv'...\n",
      "Processing '22.csv'...\n",
      "Processing '65.csv'...\n",
      "Processing '82.csv'...\n",
      "Processing '51.csv'...\n",
      "Processing '67.csv'...\n",
      "Processing '31.csv'...\n",
      "Processing '6.csv'...\n",
      "Processing '77.csv'...\n",
      "Processing '93.csv'...\n",
      "Processing '34.csv'...\n",
      "Processing '71.csv'...\n",
      "Processing '74.csv'...\n",
      "Processing '88.csv'...\n",
      "Processing '29.csv'...\n",
      "Processing '50.csv'...\n",
      "Processing '52.csv'...\n",
      "Processing '25.csv'...\n",
      "Processing '14.csv'...\n",
      "Processing '97.csv'...\n",
      "Processing '10.csv'...\n",
      "Processing '99.csv'...\n",
      "Processing '2.csv'...\n",
      "Processing '64.csv'...\n",
      "Processing '95.csv'...\n",
      "Processing '38.csv'...\n",
      "Processing '33.csv'...\n",
      "Processing '4.csv'...\n",
      "Processing '63.csv'...\n",
      "Processing '1.csv'...\n",
      "Processing '37.csv'...\n",
      "Processing '57.csv'...\n",
      "Processing '18.csv'...\n",
      "Processing '70.csv'...\n",
      "Processing '87.csv'...\n",
      "Processing '91.csv'...\n",
      "Processing '59.csv'...\n",
      "Processing '61.csv'...\n",
      "Processing '26.csv'...\n",
      "Processing '19.csv'...\n",
      "Processing '94.csv'...\n",
      "Processing '35.csv'...\n",
      "Processing '24.csv'...\n",
      "Processing '47.csv'...\n",
      "Processing '42.csv'...\n",
      "Processing '100.csv'...\n",
      "Processing '78.csv'...\n",
      "Processing '81.csv'...\n",
      "Processing '86.csv'...\n",
      "Processing '13.csv'...\n",
      "Processing '83.csv'...\n",
      "Processing '7.csv'...\n",
      "Processing '84.csv'...\n",
      "Processing '54.csv'...\n",
      "Processing '9.csv'...\n",
      "Processing '43.csv'...\n",
      "Processing '3.csv'...\n",
      "Processing '62.csv'...\n",
      "Processing '80.csv'...\n",
      "Processing '32.csv'...\n",
      "Processing '5.csv'...\n",
      "Processing '44.csv'...\n",
      "Processing '40.csv'...\n",
      "Processing '69.csv'...\n",
      "Processing '39.csv'...\n",
      "Processing '96.csv'...\n",
      "Processing '60.csv'...\n",
      "Processing '49.csv'...\n",
      "Processing '36.csv'...\n",
      "Processing '68.csv'...\n",
      "Processing '73.csv'...\n",
      "Processing '58.csv'...\n",
      "Processing '53.csv'...\n",
      "Processing '21.csv'...\n",
      "Processing '98.csv'...\n",
      "Processing '17.csv'...\n",
      "Processing '28.csv'...\n",
      "Processing '75.csv'...\n",
      "Processing '48.csv'...\n",
      "Processing '45.csv'...\n",
      "\n",
      "Batch processing finished.\n",
      "Successfully processed: 100 files.\n",
      "Errors encountered: 0 files.\n",
      "\n",
      "Creating zip archive: /home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_txt.zip...\n",
      "Successfully created zip archive: /home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_txt.zip\n"
     ]
    }
   ],
   "source": [
    "input_directory = '/home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_csv'\n",
    "\n",
    "# 2. Set the desired output directory name for the TXT files.\n",
    "output_directory = '/home/hansen/workspace/hackathon/hackson-voice-agent/data/customer_files_txt'\n",
    "\n",
    "# 3. Specify the encoding of your input CSV files (adjust if 'big5' is wrong).\n",
    "input_encoding = 'utf-8'\n",
    "\n",
    "# 4. Run the processing function.\n",
    "process_csv_folder_to_txt(\n",
    "    input_csv_dir=input_directory,\n",
    "    output_txt_dir=output_directory,\n",
    "    csv_encoding=input_encoding\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
